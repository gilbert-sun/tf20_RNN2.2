{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# View more python learning tutorial on my Youtube and Youku channel!!!\n",
    "\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\n",
    "Run this script on tensorflow r0.10. Errors appear when using lower versions.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv  \n",
    "import glob\n",
    "\n",
    "BATCH_START = 0\n",
    "TIME_STEPS = 20\n",
    "BATCH_SIZE = 50\n",
    "INPUT_SIZE = 1\n",
    "OUTPUT_SIZE = 1\n",
    "CELL_SIZE = 10\n",
    "LR = 0.006\n",
    "\n",
    "\n",
    "def get_batch():\n",
    "    global BATCH_START, TIME_STEPS\n",
    "    # xs shape (50batch, 20steps)\n",
    "    xs = np.arange(BATCH_START, BATCH_START+TIME_STEPS*BATCH_SIZE).reshape((BATCH_SIZE, TIME_STEPS)) / (10*np.pi)\n",
    "    seq = np.sin(xs)\n",
    "\n",
    "    # privide same pattern as sin\n",
    "    res = np.cos(xs)\n",
    "\n",
    "    # given sin is working too\n",
    "    res = np.sin(xs)\n",
    "\n",
    "    BATCH_START += TIME_STEPS\n",
    "    plt.plot(xs[0, :], res[0, :], 'r', xs[0, :], seq[0, :], 'b--')\n",
    "    plt.show()\n",
    "    # returned seq, res and xs: shape (batch, step, input)\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    files = glob.glob(\"./*.csv\")\n",
    "    for fileNameInput in files:\n",
    "        \n",
    "        fp = open(fileNameInput,\"r\").readlines()\n",
    "        \n",
    "        cfp = csv.DictReader(fp)\n",
    "        \n",
    "        dataset1 = list(cfp)\n",
    "        \n",
    "        N = len(fp)-1\n",
    "        Vol = [] \n",
    "        \n",
    "        for i in range(len(dataset1)):\n",
    "         \n",
    "                print (str(i)+\":\"+\"\\n\")\n",
    "         \n",
    "                try:\n",
    "                    #Vol.append() \n",
    "                    w = float( dataset1[i][\"Voltage\"].strip('\"') )\n",
    "                    w1 = float( dataset1[i-1][\"Voltage\"].strip('\"') )\n",
    "                    w2 = w1-w\n",
    "                    w3 = abs(w2)\n",
    "                    print (w)\n",
    "                    print (w1)   \n",
    "                    if(w3 > 0.4):\n",
    "                        print (\"Level4\")\n",
    "                    elif (w3 < 0.4 and w3 > 0.3):\n",
    "                        print (\"Level3\")\n",
    "                    elif (w3 < 0.3 and w3 > 0.2):\n",
    "                        print (\"Level2\")\n",
    "                    elif (w3 < 0.2 ):\n",
    "                        print (\"Level1\")\n",
    "                        \n",
    "                except ValueError:\n",
    "                    print(\"Error with row\",i,\":\",dataset1[i])\n",
    "                    pass    \n",
    "    #---------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return [seq[:, :, np.newaxis], res[:, :, np.newaxis], xs]\n",
    "\n",
    "\n",
    "class LSTMRNN(object):\n",
    "    def __init__(self, n_steps, input_size, output_size, cell_size, batch_size):\n",
    "        self.n_steps = n_steps\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.cell_size = cell_size\n",
    "        self.batch_size = batch_size\n",
    "        with tf.name_scope('inputs'):\n",
    "            self.xs = tf.placeholder(tf.float32, [None, n_steps, input_size], name='xs')\n",
    "            self.ys = tf.placeholder(tf.float32, [None, n_steps, output_size], name='ys')\n",
    "        with tf.variable_scope('in_hidden'):\n",
    "            self.add_input_layer()\n",
    "        with tf.variable_scope('LSTM_cell'):\n",
    "            self.add_cell()\n",
    "        with tf.variable_scope('out_hidden'):\n",
    "            self.add_output_layer()\n",
    "        with tf.name_scope('cost'):\n",
    "            self.compute_cost()\n",
    "        with tf.name_scope('train'):\n",
    "            self.train_op = tf.train.AdamOptimizer(LR).minimize(self.cost)\n",
    "\n",
    "    def add_input_layer(self,):\n",
    "        l_in_x = tf.reshape(self.xs, [-1, self.input_size], name='2_2D')  # (batch*n_step, in_size)\n",
    "        # Ws (in_size, cell_size)\n",
    "        Ws_in = self._weight_variable([self.input_size, self.cell_size])\n",
    "        # bs (cell_size, )\n",
    "        bs_in = self._bias_variable([self.cell_size,])\n",
    "        # l_in_y = (batch * n_steps, cell_size)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            l_in_y = tf.matmul(l_in_x, Ws_in) + bs_in\n",
    "        # reshape l_in_y ==> (batch, n_steps, cell_size)\n",
    "        self.l_in_y = tf.reshape(l_in_y, [-1, self.n_steps, self.cell_size], name='2_3D')\n",
    "\n",
    "    def add_cell(self):\n",
    "        lstm_cell = rnn.BasicLSTMCell(self.cell_size, forget_bias=1.0, state_is_tuple=True)\n",
    "        with tf.name_scope('initial_state'):\n",
    "            self.cell_init_state = lstm_cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "        self.cell_outputs, self.cell_final_state = tf.nn.dynamic_rnn(\n",
    "            lstm_cell, self.l_in_y, initial_state=self.cell_init_state, time_major=False)\n",
    "\n",
    "    def add_output_layer(self):\n",
    "        # shape = (batch * steps, cell_size)\n",
    "        l_out_x = tf.reshape(self.cell_outputs, [-1, self.cell_size], name='2_2D')\n",
    "        Ws_out = self._weight_variable([self.cell_size, self.output_size])\n",
    "        bs_out = self._bias_variable([self.output_size, ])\n",
    "        # shape = (batch * steps, output_size)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            self.pred = tf.matmul(l_out_x, Ws_out) + bs_out\n",
    "\n",
    "    def compute_cost(self):\n",
    "        with tf.name_scope('average_cost'):\n",
    "            self.cost = tf.div(\n",
    "                tf.reduce_sum(self.ms_error(\n",
    "                   tf.reshape(self.pred, [-1], name='reshape_pred'),\n",
    "                   tf.reshape(self.ys,   [-1], name='reshape_target')), name='losses_sum'),\n",
    "                self.batch_size,\n",
    "                name='average_cost')\n",
    "            tf.summary.scalar('cost', self.cost)\n",
    "\n",
    "    def ms_error(self, y_pre, y_target):\n",
    "        return tf.square(tf.subtract(y_pre, y_target))\n",
    "\n",
    "    def _weight_variable(self, shape, name='weights'):\n",
    "        initializer = tf.random_normal_initializer(mean=0., stddev=1.,)\n",
    "        return tf.get_variable(shape=shape, initializer=initializer, name=name)\n",
    "\n",
    "    def _bias_variable(self, shape, name='biases'):\n",
    "        initializer = tf.constant_initializer(0.1)\n",
    "        return tf.get_variable(name=name, shape=shape, initializer=initializer)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = LSTMRNN(TIME_STEPS, INPUT_SIZE, OUTPUT_SIZE, CELL_SIZE, BATCH_SIZE)\n",
    "    sess = tf.Session()\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"logs\", sess.graph)\n",
    "    # tf.initialize_all_variables() no long valid\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # relocate to the local dir and run this line to view it on Chrome (http://0.0.0.0:6006/):\n",
    "    # $ tensorboard --logdir='logs'\n",
    "\n",
    "    plt.ion()\n",
    "    plt.show()\n",
    "    for i in range(200):\n",
    "        seq, res, xs = get_batch()\n",
    "        if i == 0:\n",
    "            feed_dict = {\n",
    "                    model.xs: seq,\n",
    "                    model.ys: res,\n",
    "                    # create initial state\n",
    "            }\n",
    "        else:\n",
    "            feed_dict = {\n",
    "                model.xs: seq,\n",
    "                model.ys: res,\n",
    "                model.cell_init_state: state    # use last state as the initial state for this run\n",
    "            }\n",
    "\n",
    "        _, cost, state, pred = sess.run(\n",
    "            [model.train_op, model.cost, model.cell_final_state, model.pred],\n",
    "            feed_dict=feed_dict)\n",
    "\n",
    "        # plotting\n",
    "\n",
    "\t# print('xs:')\n",
    "\t# print(xs[0,:])\n",
    "\t# print('pred:')\n",
    "\t# print(pred.flatten()[:TIME_STEPS])\n",
    "\n",
    "\t# only the first 20 samples are ploted\n",
    "        plt.plot(xs[0, :], res[0].flatten(), 'r', xs[0, :], pred.flatten()[:TIME_STEPS], 'b--')\n",
    "\n",
    "\t# entirely plot the all 50x20 samples\n",
    "        plt.plot(xs[:].flatten(), res[:].flatten(), 'r', xs[:].flatten(), pred[:].flatten(), 'b--')\n",
    "\n",
    "        plt.ylim((-1.2, 1.2))\n",
    "        plt.draw()\n",
    "        plt.pause(0.3)\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print('cost: ', round(cost, 4))\n",
    "            result = sess.run(merged, feed_dict)\n",
    "            writer.add_summary(result, i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
